{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Labeling the genre to number and vice versa\n",
    "def label2int(ch):\n",
    "    asciiVal = ord(ch)\n",
    "    if(asciiVal<=57): #0-9\n",
    "        asciiVal-=48\n",
    "    elif(asciiVal<=90): #A-Z\n",
    "        asciiVal-=55\n",
    "    else: #a-z\n",
    "        asciiVal-=61\n",
    "    return asciiVal\n",
    "    \n",
    "def int2label(i):\n",
    "    if(i<=9): #0-9\n",
    "        i+=48\n",
    "    elif(i<=35): #A-Z\n",
    "        i+=55\n",
    "    else: #a-z\n",
    "        i+=61\n",
    "    return chr(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from skimage.feature import canny\n",
    "from skimage.morphology import reconstruction\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.filters import threshold_otsu\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Path for data\n",
    "path = os.getcwd()\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 40, 25\n",
    "\n",
    "# Keep or not the initial image aspect ratio\n",
    "keepRatio = False\n",
    "\n",
    "# Suffix of the created directories and files\n",
    "suffix = \"Preproc_\" + str(img_rows) + \"_\"+ str(img_cols) + (\"_kr\" if keepRatio else \"\")\n",
    "\n",
    "# Create the directories if needed\n",
    "if not os.path.exists(os.getcwd()+\"/data/train\"+suffix ):\n",
    "    os.makedirs(os.getcwd()+\"/data/train\"+suffix)\n",
    "if not os.path.exists( os.getcwd()+\"/data/test\"+suffix ):\n",
    "    os.makedirs(os.getcwd()+\"/data/test\"+suffix)\n",
    "    \n",
    "    \n",
    "### Images preprocessing ###\n",
    "\n",
    "for setType in [\"train\", \"test\"]:\n",
    "    files = natsorted(glob.glob(os.getcwd()+\"/data/\"+setType+\"/*\"))\n",
    "    data = np.zeros((len(files), img_rows, img_cols)) \n",
    "    \n",
    "    for i, filepath in enumerate(files):\n",
    "        image = imread(filepath, True) #True: grayscale\n",
    "\n",
    "        if keepRatio:\n",
    "            maxSize = max(image.shape[0], image.shape[1])\n",
    "            \n",
    "            # Size of the resized image, keeping aspect ratio\n",
    "            imageWidth = math.floor(img_rows*image.shape[0]/maxSize)\n",
    "            imageHeigh = math.floor(img_cols*image.shape[1]/maxSize)\n",
    "            \n",
    "            # Compute deltas to center image \n",
    "            dRows = (img_rows-imageWidth)//2\n",
    "            dCols = (img_cols-imageHeigh)//2\n",
    "                        \n",
    "            imageResized = np.zeros((img_rows, img_cols))\n",
    "            imageResized[dRows:dRows+imageWidth, dCols:dCols+imageHeigh] = imresize(image, (imageWidth, imageHeigh))\n",
    "            \n",
    "            # Fill the empty image with the median value of the border pixels\n",
    "            val = np.median(np.append(imageResized[dRows,:],\n",
    "                                      (imageResized[dRows+imageWidth-1,:],\n",
    "                                      imageResized[:,dCols],\n",
    "                                      imageResized[:,dCols+imageHeigh-1])))\n",
    "                                      \n",
    "            # If rows were left blank\n",
    "            if(dRows>0):\n",
    "                imageResized[0:dRows,:].fill(val)\n",
    "                imageResized[dRows+imageWidth:,:].fill(val)\n",
    "                \n",
    "            # If columns were left blank\n",
    "            if(dCols>0):\n",
    "                imageResized[:,0:dCols].fill(val)\n",
    "                imageResized[:,dCols+imageHeigh:].fill(val)\n",
    "        else:\n",
    "            imageResized = imresize(image, (img_rows, img_cols))\n",
    "            \n",
    "        data[i] = imageResized\n",
    "        \n",
    "    data = data[:,np.newaxis,:,:] \n",
    "    \n",
    "    # Makes values floats between 0 and 1\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    \n",
    "    # Save the data as numpy file\n",
    "    np.save(os.getcwd()+\"/data/\"+setType+suffix+\".npy\", data)\n",
    "\n",
    "    \n",
    "### Labels preprocessing ###\n",
    "\n",
    "# Load labels\n",
    "y_train = pd.read_csv(os.getcwd()+\"/data/trainLabels.csv\").values[:,1] #Keep only label\n",
    "\n",
    "# Convert labels to one-hot vector\n",
    "Y_train = np.zeros((y_train.shape[0], len(np.unique(y_train))))\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    Y_train[i][label2int(y_train[i])] = 1 # One-hot\n",
    "\n",
    "# Save preprocessed label to numpy file\n",
    "np.save(os.getcwd()+\"/data/\"+\"labelsPreproc.npy\", Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 4.0593 - acc: 0.0507 Epoch 00000: val_acc improved from -inf to 0.04328, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 294s - loss: 4.0525 - acc: 0.0514 - val_loss: 3.8454 - val_acc: 0.0433\n",
      "Epoch 2/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 3.8526 - acc: 0.0650 Epoch 00001: val_acc improved from 0.04328 to 0.08339, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 300s - loss: 3.8559 - acc: 0.0649 - val_loss: 3.8705 - val_acc: 0.0834\n",
      "Epoch 3/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 3.7804 - acc: 0.0813 Epoch 00002: val_acc improved from 0.08339 to 0.09930, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 297s - loss: 3.7805 - acc: 0.0821 - val_loss: 3.6091 - val_acc: 0.0993\n",
      "Epoch 4/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 3.8027 - acc: 0.0867 Epoch 00003: val_acc improved from 0.09930 to 0.12731, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 290s - loss: 3.8040 - acc: 0.0876 - val_loss: 3.7417 - val_acc: 0.1273\n",
      "Epoch 5/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 3.6747 - acc: 0.1220 Epoch 00004: val_acc improved from 0.12731 to 0.25016, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 293s - loss: 3.6721 - acc: 0.1231 - val_loss: 3.2340 - val_acc: 0.2502\n",
      "Epoch 6/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 3.4518 - acc: 0.1628 Epoch 00005: val_acc did not improve\n",
      "4712/4712 [==============================] - 300s - loss: 3.4452 - acc: 0.1640 - val_loss: 3.3742 - val_acc: 0.1712\n",
      "Epoch 7/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 3.3400 - acc: 0.1865 Epoch 00006: val_acc improved from 0.25016 to 0.39847, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 296s - loss: 3.3350 - acc: 0.1876 - val_loss: 2.4486 - val_acc: 0.3985\n",
      "Epoch 8/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 3.3312 - acc: 0.2035 Epoch 00007: val_acc did not improve\n",
      "4712/4712 [==============================] - 302s - loss: 3.3343 - acc: 0.2020 - val_loss: 2.9385 - val_acc: 0.3132\n",
      "Epoch 9/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 2.9040 - acc: 0.2704 Epoch 00008: val_acc improved from 0.39847 to 0.42648, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 293s - loss: 2.8993 - acc: 0.2708 - val_loss: 2.0289 - val_acc: 0.4265\n",
      "Epoch 10/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 2.7604 - acc: 0.2967 Epoch 00009: val_acc improved from 0.42648 to 0.45003, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 294s - loss: 2.7551 - acc: 0.2992 - val_loss: 1.9730 - val_acc: 0.4500\n",
      "Epoch 11/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 2.4539 - acc: 0.3600 Epoch 00010: val_acc improved from 0.45003 to 0.58880, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 293s - loss: 2.4496 - acc: 0.3612 - val_loss: 1.5352 - val_acc: 0.5888\n",
      "Epoch 12/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 2.3555 - acc: 0.3809 Epoch 00011: val_acc did not improve\n",
      "4712/4712 [==============================] - 302s - loss: 2.3504 - acc: 0.3829 - val_loss: 1.4095 - val_acc: 0.5742\n",
      "Epoch 13/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 2.1464 - acc: 0.4265 Epoch 00012: val_acc improved from 0.58880 to 0.60471, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 303s - loss: 2.1397 - acc: 0.4287 - val_loss: 1.3775 - val_acc: 0.6047\n",
      "Epoch 14/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 2.0516 - acc: 0.4533 Epoch 00013: val_acc improved from 0.60471 to 0.61617, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 298s - loss: 2.0403 - acc: 0.4552 - val_loss: 1.2739 - val_acc: 0.6162\n",
      "Epoch 15/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.8977 - acc: 0.4909 Epoch 00014: val_acc improved from 0.61617 to 0.70083, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 301s - loss: 1.8914 - acc: 0.4919 - val_loss: 1.0597 - val_acc: 0.7008\n",
      "Epoch 16/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.8200 - acc: 0.5039 Epoch 00015: val_acc did not improve\n",
      "4712/4712 [==============================] - 292s - loss: 1.8102 - acc: 0.5079 - val_loss: 1.0166 - val_acc: 0.6932\n",
      "Epoch 17/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.6936 - acc: 0.5376 Epoch 00016: val_acc improved from 0.70083 to 0.70592, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 294s - loss: 1.6926 - acc: 0.5374 - val_loss: 1.0214 - val_acc: 0.7059\n",
      "Epoch 18/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.6104 - acc: 0.5535 Epoch 00017: val_acc improved from 0.70592 to 0.72311, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 299s - loss: 1.6117 - acc: 0.5528 - val_loss: 0.9695 - val_acc: 0.7231\n",
      "Epoch 19/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.5490 - acc: 0.5715 Epoch 00018: val_acc improved from 0.72311 to 0.73902, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 295s - loss: 1.5434 - acc: 0.5728 - val_loss: 0.8853 - val_acc: 0.7390\n",
      "Epoch 20/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.4092 - acc: 0.6078 Epoch 00019: val_acc improved from 0.73902 to 0.75621, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 302s - loss: 1.4089 - acc: 0.6072 - val_loss: 0.8855 - val_acc: 0.7562\n",
      "Epoch 21/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.3802 - acc: 0.5983 Epoch 00020: val_acc did not improve\n",
      "4712/4712 [==============================] - 299s - loss: 1.3799 - acc: 0.5974 - val_loss: 0.9252 - val_acc: 0.7358\n",
      "Epoch 22/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.3371 - acc: 0.6191 Epoch 00021: val_acc did not improve\n",
      "4712/4712 [==============================] - 297s - loss: 1.3403 - acc: 0.6182 - val_loss: 0.9997 - val_acc: 0.7078\n",
      "Epoch 23/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.2664 - acc: 0.6409 Epoch 00022: val_acc did not improve\n",
      "4712/4712 [==============================] - 308s - loss: 1.2670 - acc: 0.6405 - val_loss: 0.8949 - val_acc: 0.7377\n",
      "Epoch 24/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.2485 - acc: 0.6343 Epoch 00023: val_acc did not improve\n",
      "4712/4712 [==============================] - 302s - loss: 1.2502 - acc: 0.6343 - val_loss: 0.8487 - val_acc: 0.7537\n",
      "Epoch 25/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.1875 - acc: 0.6587 Epoch 00024: val_acc improved from 0.75621 to 0.77721, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 297s - loss: 1.1839 - acc: 0.6596 - val_loss: 0.8182 - val_acc: 0.7772\n",
      "Epoch 26/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.1785 - acc: 0.6591 Epoch 00025: val_acc did not improve\n",
      "4712/4712 [==============================] - 297s - loss: 1.1766 - acc: 0.6598 - val_loss: 0.8344 - val_acc: 0.7467\n",
      "Epoch 27/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.1223 - acc: 0.6713 Epoch 00026: val_acc did not improve\n",
      "4712/4712 [==============================] - 292s - loss: 1.1215 - acc: 0.6702 - val_loss: 0.7812 - val_acc: 0.7689\n",
      "Epoch 28/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.1240 - acc: 0.6811 Epoch 00027: val_acc improved from 0.77721 to 0.78039, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 298s - loss: 1.1190 - acc: 0.6829 - val_loss: 0.7839 - val_acc: 0.7804\n",
      "Epoch 29/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.0716 - acc: 0.6793 Epoch 00028: val_acc did not improve\n",
      "4712/4712 [==============================] - 296s - loss: 1.0708 - acc: 0.6789 - val_loss: 0.8651 - val_acc: 0.7454\n",
      "Epoch 30/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.0264 - acc: 0.6976 Epoch 00029: val_acc did not improve\n",
      "4712/4712 [==============================] - 303s - loss: 1.0256 - acc: 0.6974 - val_loss: 0.7392 - val_acc: 0.7759\n",
      "Epoch 31/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 1.0131 - acc: 0.7050 Epoch 00030: val_acc did not improve\n",
      "4712/4712 [==============================] - 291s - loss: 1.0107 - acc: 0.7065 - val_loss: 0.7905 - val_acc: 0.7613\n",
      "Epoch 32/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.9916 - acc: 0.7061 Epoch 00031: val_acc did not improve\n",
      "4712/4712 [==============================] - 303s - loss: 0.9900 - acc: 0.7052 - val_loss: 0.8801 - val_acc: 0.7346\n",
      "Epoch 33/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.9887 - acc: 0.7065 Epoch 00032: val_acc did not improve\n",
      "4712/4712 [==============================] - 292s - loss: 0.9875 - acc: 0.7069 - val_loss: 0.8070 - val_acc: 0.7740\n",
      "Epoch 34/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.9498 - acc: 0.7133 Epoch 00033: val_acc improved from 0.78039 to 0.78676, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 289s - loss: 0.9533 - acc: 0.7131 - val_loss: 0.7540 - val_acc: 0.7868\n",
      "Epoch 35/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.9417 - acc: 0.7239 Epoch 00034: val_acc did not improve\n",
      "4712/4712 [==============================] - 288s - loss: 0.9417 - acc: 0.7233 - val_loss: 0.7338 - val_acc: 0.7683\n",
      "Epoch 36/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.9022 - acc: 0.7320 Epoch 00035: val_acc did not improve\n",
      "4712/4712 [==============================] - 288s - loss: 0.9040 - acc: 0.7307 - val_loss: 0.7254 - val_acc: 0.7810\n",
      "Epoch 37/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.9004 - acc: 0.7298 Epoch 00036: val_acc did not improve\n",
      "4712/4712 [==============================] - 288s - loss: 0.9070 - acc: 0.7288 - val_loss: 0.8526 - val_acc: 0.7307\n",
      "Epoch 38/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.9135 - acc: 0.7239 Epoch 00037: val_acc improved from 0.78676 to 0.79185, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 299s - loss: 0.9168 - acc: 0.7233 - val_loss: 0.6762 - val_acc: 0.7919\n",
      "Epoch 39/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.8652 - acc: 0.7348 Epoch 00038: val_acc did not improve\n",
      "4712/4712 [==============================] - 292s - loss: 0.8693 - acc: 0.7337 - val_loss: 0.7416 - val_acc: 0.7728\n",
      "Epoch 40/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.8605 - acc: 0.7441 Epoch 00039: val_acc did not improve\n",
      "4712/4712 [==============================] - 295s - loss: 0.8610 - acc: 0.7449 - val_loss: 0.7067 - val_acc: 0.7874\n",
      "Epoch 41/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.8418 - acc: 0.7428 Epoch 00040: val_acc improved from 0.79185 to 0.80713, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 294s - loss: 0.8416 - acc: 0.7421 - val_loss: 0.7029 - val_acc: 0.8071\n",
      "Epoch 42/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7941 - acc: 0.7491 Epoch 00041: val_acc did not improve\n",
      "4712/4712 [==============================] - 291s - loss: 0.7989 - acc: 0.7479 - val_loss: 0.6883 - val_acc: 0.7829\n",
      "Epoch 43/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7881 - acc: 0.7563 Epoch 00042: val_acc did not improve\n",
      "4712/4712 [==============================] - 290s - loss: 0.7941 - acc: 0.7564 - val_loss: 0.6860 - val_acc: 0.8027\n",
      "Epoch 44/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7926 - acc: 0.7587 Epoch 00043: val_acc did not improve\n",
      "4712/4712 [==============================] - 296s - loss: 0.7895 - acc: 0.7585 - val_loss: 0.6891 - val_acc: 0.8059\n",
      "Epoch 45/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.8101 - acc: 0.7570 Epoch 00044: val_acc improved from 0.80713 to 0.80777, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 291s - loss: 0.8118 - acc: 0.7564 - val_loss: 0.6423 - val_acc: 0.8078\n",
      "Epoch 46/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7835 - acc: 0.7580 Epoch 00045: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.7810 - acc: 0.7596 - val_loss: 0.6921 - val_acc: 0.7842\n",
      "Epoch 47/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7499 - acc: 0.7643 Epoch 00046: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.7521 - acc: 0.7642 - val_loss: 0.7071 - val_acc: 0.8014\n",
      "Epoch 48/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7712 - acc: 0.7572 Epoch 00047: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.7689 - acc: 0.7581 - val_loss: 0.6727 - val_acc: 0.8008\n",
      "Epoch 49/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7299 - acc: 0.7709 Epoch 00048: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.7352 - acc: 0.7691 - val_loss: 0.6886 - val_acc: 0.7874\n",
      "Epoch 50/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7265 - acc: 0.7707 Epoch 00049: val_acc did not improve\n",
      "4712/4712 [==============================] - 294s - loss: 0.7334 - acc: 0.7693 - val_loss: 0.6421 - val_acc: 0.7938\n",
      "Epoch 51/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7235 - acc: 0.7807 Epoch 00050: val_acc did not improve\n",
      "4712/4712 [==============================] - 292s - loss: 0.7215 - acc: 0.7799 - val_loss: 0.7155 - val_acc: 0.7899\n",
      "Epoch 52/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7083 - acc: 0.7759 Epoch 00051: val_acc improved from 0.80777 to 0.80777, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 298s - loss: 0.7105 - acc: 0.7753 - val_loss: 0.6558 - val_acc: 0.8078\n",
      "Epoch 53/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6893 - acc: 0.7846 Epoch 00052: val_acc did not improve\n",
      "4712/4712 [==============================] - 290s - loss: 0.6934 - acc: 0.7829 - val_loss: 0.7226 - val_acc: 0.7747\n",
      "Epoch 54/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.7130 - acc: 0.7739 Epoch 00053: val_acc did not improve\n",
      "4712/4712 [==============================] - 290s - loss: 0.7125 - acc: 0.7750 - val_loss: 0.6843 - val_acc: 0.7912\n",
      "Epoch 55/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6580 - acc: 0.7852 Epoch 00054: val_acc did not improve\n",
      "4712/4712 [==============================] - 298s - loss: 0.6603 - acc: 0.7842 - val_loss: 0.7822 - val_acc: 0.7759\n",
      "Epoch 56/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6641 - acc: 0.7878 Epoch 00055: val_acc improved from 0.80777 to 0.81031, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 293s - loss: 0.6639 - acc: 0.7869 - val_loss: 0.6363 - val_acc: 0.8103\n",
      "Epoch 57/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6712 - acc: 0.7848 Epoch 00056: val_acc did not improve\n",
      "4712/4712 [==============================] - 295s - loss: 0.6696 - acc: 0.7857 - val_loss: 0.7738 - val_acc: 0.7931\n",
      "Epoch 58/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6576 - acc: 0.7915 Epoch 00057: val_acc did not improve\n",
      "4712/4712 [==============================] - 295s - loss: 0.6595 - acc: 0.7901 - val_loss: 0.7083 - val_acc: 0.7976\n",
      "Epoch 59/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6483 - acc: 0.7972 Epoch 00058: val_acc improved from 0.81031 to 0.81604, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 302s - loss: 0.6477 - acc: 0.7978 - val_loss: 0.6257 - val_acc: 0.8160\n",
      "Epoch 60/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6343 - acc: 0.7985 Epoch 00059: val_acc improved from 0.81604 to 0.81922, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 296s - loss: 0.6322 - acc: 0.7992 - val_loss: 0.6472 - val_acc: 0.8192\n",
      "Epoch 61/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6649 - acc: 0.7915 Epoch 00060: val_acc did not improve\n",
      "4712/4712 [==============================] - 297s - loss: 0.6647 - acc: 0.7922 - val_loss: 0.6538 - val_acc: 0.8090\n",
      "Epoch 62/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6098 - acc: 0.8015 Epoch 00061: val_acc did not improve\n",
      "4712/4712 [==============================] - 292s - loss: 0.6099 - acc: 0.8026 - val_loss: 0.6296 - val_acc: 0.8065\n",
      "Epoch 63/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6320 - acc: 0.8000 Epoch 00062: val_acc did not improve\n",
      "4712/4712 [==============================] - 290s - loss: 0.6330 - acc: 0.7992 - val_loss: 0.6245 - val_acc: 0.7995\n",
      "Epoch 64/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6095 - acc: 0.8080 Epoch 00063: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.6119 - acc: 0.8073 - val_loss: 0.6532 - val_acc: 0.7868\n",
      "Epoch 65/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5934 - acc: 0.8063 Epoch 00064: val_acc did not improve\n",
      "4712/4712 [==============================] - 290s - loss: 0.5945 - acc: 0.8062 - val_loss: 0.6219 - val_acc: 0.8154\n",
      "Epoch 66/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5669 - acc: 0.8143 Epoch 00065: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.5681 - acc: 0.8143 - val_loss: 0.6647 - val_acc: 0.7798\n",
      "Epoch 67/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5913 - acc: 0.8124 Epoch 00066: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.5923 - acc: 0.8124 - val_loss: 0.6588 - val_acc: 0.8065\n",
      "Epoch 68/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5963 - acc: 0.8085 Epoch 00067: val_acc did not improve\n",
      "4712/4712 [==============================] - 289s - loss: 0.5977 - acc: 0.8073 - val_loss: 0.7070 - val_acc: 0.7658\n",
      "Epoch 69/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5675 - acc: 0.8154 Epoch 00068: val_acc did not improve\n",
      "4712/4712 [==============================] - 311s - loss: 0.5710 - acc: 0.8145 - val_loss: 0.6196 - val_acc: 0.8167\n",
      "Epoch 70/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.6012 - acc: 0.8083 Epoch 00069: val_acc did not improve\n",
      "4712/4712 [==============================] - 293s - loss: 0.6042 - acc: 0.8079 - val_loss: 0.6769 - val_acc: 0.8039\n",
      "Epoch 71/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5863 - acc: 0.8074 Epoch 00070: val_acc did not improve\n",
      "4712/4712 [==============================] - 287s - loss: 0.5857 - acc: 0.8069 - val_loss: 0.6585 - val_acc: 0.8160\n",
      "Epoch 72/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5452 - acc: 0.8187 Epoch 00071: val_acc did not improve\n",
      "4712/4712 [==============================] - 311s - loss: 0.5474 - acc: 0.8194 - val_loss: 0.6479 - val_acc: 0.8020\n",
      "Epoch 73/500\n",
      "4600/4712 [============================>.] - ETA: 7s - loss: 0.5661 - acc: 0.8107 Epoch 00072: val_acc improved from 0.81922 to 0.82113, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 326s - loss: 0.5624 - acc: 0.8113 - val_loss: 0.6544 - val_acc: 0.8211\n",
      "Epoch 74/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5400 - acc: 0.8176 Epoch 00073: val_acc did not improve\n",
      "4712/4712 [==============================] - 310s - loss: 0.5446 - acc: 0.8166 - val_loss: 0.6580 - val_acc: 0.8148\n",
      "Epoch 75/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5578 - acc: 0.8178 Epoch 00074: val_acc improved from 0.82113 to 0.82368, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 310s - loss: 0.5542 - acc: 0.8185 - val_loss: 0.6745 - val_acc: 0.8237\n",
      "Epoch 76/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5355 - acc: 0.8270 Epoch 00075: val_acc did not improve\n",
      "4712/4712 [==============================] - 311s - loss: 0.5326 - acc: 0.8279 - val_loss: 0.6318 - val_acc: 0.8129\n",
      "Epoch 77/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5330 - acc: 0.8224 Epoch 00076: val_acc did not improve\n",
      "4712/4712 [==============================] - 313s - loss: 0.5376 - acc: 0.8219 - val_loss: 0.6268 - val_acc: 0.8211\n",
      "Epoch 78/500\n",
      "4600/4712 [============================>.] - ETA: 7s - loss: 0.5258 - acc: 0.8237 Epoch 00077: val_acc did not improve\n",
      "4712/4712 [==============================] - 327s - loss: 0.5229 - acc: 0.8247 - val_loss: 0.6328 - val_acc: 0.8211\n",
      "Epoch 79/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5337 - acc: 0.8259 Epoch 00078: val_acc did not improve\n",
      "4712/4712 [==============================] - 324s - loss: 0.5346 - acc: 0.8253 - val_loss: 0.6432 - val_acc: 0.8135\n",
      "Epoch 80/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5363 - acc: 0.8265 Epoch 00079: val_acc did not improve\n",
      "4712/4712 [==============================] - 320s - loss: 0.5393 - acc: 0.8264 - val_loss: 0.6277 - val_acc: 0.8122\n",
      "Epoch 81/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5157 - acc: 0.8341 Epoch 00080: val_acc improved from 0.82368 to 0.83004, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 309s - loss: 0.5155 - acc: 0.8343 - val_loss: 0.6023 - val_acc: 0.8300\n",
      "Epoch 82/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4907 - acc: 0.8367 Epoch 00081: val_acc did not improve\n",
      "4712/4712 [==============================] - 314s - loss: 0.4918 - acc: 0.8366 - val_loss: 0.6264 - val_acc: 0.8250\n",
      "Epoch 83/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4924 - acc: 0.8315 Epoch 00082: val_acc improved from 0.83004 to 0.83450, saving model to best.kerasModelWeights\n",
      "4712/4712 [==============================] - 323s - loss: 0.4927 - acc: 0.8315 - val_loss: 0.5937 - val_acc: 0.8345\n",
      "Epoch 84/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4738 - acc: 0.8404 Epoch 00083: val_acc did not improve\n",
      "4712/4712 [==============================] - 324s - loss: 0.4799 - acc: 0.8387 - val_loss: 0.6758 - val_acc: 0.7938\n",
      "Epoch 85/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4634 - acc: 0.8391 Epoch 00084: val_acc did not improve\n",
      "4712/4712 [==============================] - 314s - loss: 0.4628 - acc: 0.8391 - val_loss: 0.6318 - val_acc: 0.8173\n",
      "Epoch 86/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.5098 - acc: 0.8315 Epoch 00085: val_acc did not improve\n",
      "4712/4712 [==============================] - 317s - loss: 0.5125 - acc: 0.8306 - val_loss: 0.6338 - val_acc: 0.8097\n",
      "Epoch 87/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4812 - acc: 0.8411 Epoch 00086: val_acc did not improve\n",
      "4712/4712 [==============================] - 321s - loss: 0.4803 - acc: 0.8419 - val_loss: 0.6172 - val_acc: 0.8078\n",
      "Epoch 88/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4712 - acc: 0.8383 Epoch 00087: val_acc did not improve\n",
      "4712/4712 [==============================] - 317s - loss: 0.4709 - acc: 0.8387 - val_loss: 0.6490 - val_acc: 0.8097\n",
      "Epoch 89/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4412 - acc: 0.8483 Epoch 00088: val_acc did not improve\n",
      "4712/4712 [==============================] - 313s - loss: 0.4419 - acc: 0.8476 - val_loss: 0.6315 - val_acc: 0.8090\n",
      "Epoch 90/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4712 - acc: 0.8389 Epoch 00089: val_acc did not improve\n",
      "4712/4712 [==============================] - 321s - loss: 0.4740 - acc: 0.8376 - val_loss: 0.6422 - val_acc: 0.7989\n",
      "Epoch 91/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4611 - acc: 0.8409 Epoch 00090: val_acc did not improve\n",
      "4712/4712 [==============================] - 314s - loss: 0.4609 - acc: 0.8402 - val_loss: 0.6489 - val_acc: 0.8129\n",
      "Epoch 92/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4427 - acc: 0.8580 Epoch 00091: val_acc did not improve\n",
      "4712/4712 [==============================] - 314s - loss: 0.4417 - acc: 0.8580 - val_loss: 0.6335 - val_acc: 0.8224\n",
      "Epoch 93/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4533 - acc: 0.8498 Epoch 00092: val_acc did not improve\n",
      "4712/4712 [==============================] - 313s - loss: 0.4520 - acc: 0.8502 - val_loss: 0.6519 - val_acc: 0.8173\n",
      "Epoch 94/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4652 - acc: 0.8441 Epoch 00093: val_acc did not improve\n",
      "4712/4712 [==============================] - 317s - loss: 0.4623 - acc: 0.8442 - val_loss: 0.6396 - val_acc: 0.8129\n",
      "Epoch 95/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4473 - acc: 0.8485 Epoch 00094: val_acc did not improve\n",
      "4712/4712 [==============================] - 310s - loss: 0.4427 - acc: 0.8504 - val_loss: 0.6739 - val_acc: 0.8046\n",
      "Epoch 96/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4337 - acc: 0.8509 Epoch 00095: val_acc did not improve\n",
      "4712/4712 [==============================] - 320s - loss: 0.4372 - acc: 0.8506 - val_loss: 0.6212 - val_acc: 0.8199\n",
      "Epoch 97/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4544 - acc: 0.8430 Epoch 00096: val_acc did not improve\n",
      "4712/4712 [==============================] - 310s - loss: 0.4583 - acc: 0.8417 - val_loss: 0.6496 - val_acc: 0.8078\n",
      "Epoch 98/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4321 - acc: 0.8561 Epoch 00097: val_acc did not improve\n",
      "4712/4712 [==============================] - 310s - loss: 0.4306 - acc: 0.8572 - val_loss: 0.6436 - val_acc: 0.8173\n",
      "Epoch 99/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4397 - acc: 0.8509 Epoch 00098: val_acc did not improve\n",
      "4712/4712 [==============================] - 316s - loss: 0.4367 - acc: 0.8512 - val_loss: 0.6674 - val_acc: 0.8300\n",
      "Epoch 100/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4315 - acc: 0.8511 Epoch 00099: val_acc did not improve\n",
      "4712/4712 [==============================] - 313s - loss: 0.4304 - acc: 0.8519 - val_loss: 0.6488 - val_acc: 0.8262\n",
      "Epoch 101/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4055 - acc: 0.8578 Epoch 00100: val_acc did not improve\n",
      "4712/4712 [==============================] - 308s - loss: 0.4057 - acc: 0.8584 - val_loss: 0.5982 - val_acc: 0.8192\n",
      "Epoch 102/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4228 - acc: 0.8559 Epoch 00101: val_acc did not improve\n",
      "4712/4712 [==============================] - 316s - loss: 0.4223 - acc: 0.8563 - val_loss: 0.6442 - val_acc: 0.8116\n",
      "Epoch 103/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4161 - acc: 0.8589 Epoch 00102: val_acc did not improve\n",
      "4712/4712 [==============================] - 315s - loss: 0.4165 - acc: 0.8587 - val_loss: 0.6450 - val_acc: 0.8135\n",
      "Epoch 104/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4023 - acc: 0.8613 Epoch 00103: val_acc did not improve\n",
      "4712/4712 [==============================] - 311s - loss: 0.4061 - acc: 0.8595 - val_loss: 0.6236 - val_acc: 0.8250\n",
      "Epoch 105/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3995 - acc: 0.8648 Epoch 00104: val_acc did not improve\n",
      "4712/4712 [==============================] - 314s - loss: 0.3982 - acc: 0.8652 - val_loss: 0.6290 - val_acc: 0.8288\n",
      "Epoch 106/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3870 - acc: 0.8672 Epoch 00105: val_acc did not improve\n",
      "4712/4712 [==============================] - 310s - loss: 0.3876 - acc: 0.8671 - val_loss: 0.6482 - val_acc: 0.8192\n",
      "Epoch 107/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4056 - acc: 0.8600 Epoch 00106: val_acc did not improve\n",
      "4712/4712 [==============================] - 313s - loss: 0.4064 - acc: 0.8595 - val_loss: 0.7039 - val_acc: 0.8109\n",
      "Epoch 108/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.4222 - acc: 0.8583 Epoch 00107: val_acc did not improve\n",
      "4712/4712 [==============================] - 309s - loss: 0.4208 - acc: 0.8587 - val_loss: 0.6458 - val_acc: 0.8218\n",
      "Epoch 109/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3781 - acc: 0.8665 Epoch 00108: val_acc did not improve\n",
      "4712/4712 [==============================] - 322s - loss: 0.3776 - acc: 0.8663 - val_loss: 0.7317 - val_acc: 0.8205\n",
      "Epoch 110/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3946 - acc: 0.8643 Epoch 00109: val_acc did not improve\n",
      "4712/4712 [==============================] - 315s - loss: 0.3965 - acc: 0.8631 - val_loss: 0.6810 - val_acc: 0.8001\n",
      "Epoch 111/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3826 - acc: 0.8670 Epoch 00110: val_acc did not improve\n",
      "4712/4712 [==============================] - 318s - loss: 0.3802 - acc: 0.8678 - val_loss: 0.6968 - val_acc: 0.8300\n",
      "Epoch 112/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3616 - acc: 0.8759 Epoch 00111: val_acc did not improve\n",
      "4712/4712 [==============================] - 318s - loss: 0.3634 - acc: 0.8752 - val_loss: 0.7624 - val_acc: 0.7931\n",
      "Epoch 113/500\n",
      "4600/4712 [============================>.] - ETA: 7s - loss: 0.3860 - acc: 0.8665 Epoch 00112: val_acc did not improve\n",
      "4712/4712 [==============================] - 332s - loss: 0.3853 - acc: 0.8667 - val_loss: 0.6878 - val_acc: 0.8300\n",
      "Epoch 114/500\n",
      "4600/4712 [============================>.] - ETA: 7s - loss: 0.3826 - acc: 0.8637 Epoch 00113: val_acc did not improve\n",
      "4712/4712 [==============================] - 327s - loss: 0.3795 - acc: 0.8650 - val_loss: 0.7431 - val_acc: 0.8199\n",
      "Epoch 115/500\n",
      "4600/4712 [============================>.] - ETA: 7s - loss: 0.3881 - acc: 0.8663 Epoch 00114: val_acc did not improve\n",
      "4712/4712 [==============================] - 330s - loss: 0.3866 - acc: 0.8669 - val_loss: 0.6828 - val_acc: 0.8186\n",
      "Epoch 116/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3701 - acc: 0.8680 Epoch 00115: val_acc did not improve\n",
      "4712/4712 [==============================] - 322s - loss: 0.3693 - acc: 0.8688 - val_loss: 0.7253 - val_acc: 0.8250\n",
      "Epoch 117/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3756 - acc: 0.8717 Epoch 00116: val_acc did not improve\n",
      "4712/4712 [==============================] - 320s - loss: 0.3798 - acc: 0.8712 - val_loss: 0.6725 - val_acc: 0.8116\n",
      "Epoch 118/500\n",
      "4600/4712 [============================>.] - ETA: 7s - loss: 0.3744 - acc: 0.8693 Epoch 00117: val_acc did not improve\n",
      "4712/4712 [==============================] - 327s - loss: 0.3732 - acc: 0.8699 - val_loss: 0.6509 - val_acc: 0.8167\n",
      "Epoch 119/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3617 - acc: 0.8704 Epoch 00118: val_acc did not improve\n",
      "4712/4712 [==============================] - 314s - loss: 0.3583 - acc: 0.8716 - val_loss: 0.6452 - val_acc: 0.8300\n",
      "Epoch 120/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3728 - acc: 0.8713 Epoch 00119: val_acc did not improve\n",
      "4712/4712 [==============================] - 320s - loss: 0.3698 - acc: 0.8725 - val_loss: 0.6973 - val_acc: 0.8186\n",
      "Epoch 121/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3486 - acc: 0.8811 Epoch 00120: val_acc did not improve\n",
      "4712/4712 [==============================] - 309s - loss: 0.3482 - acc: 0.8814 - val_loss: 0.6574 - val_acc: 0.8269\n",
      "Epoch 122/500\n",
      "4600/4712 [============================>.] - ETA: 26s - loss: 0.3497 - acc: 0.8754Epoch 00121: val_acc did not improve\n",
      "4712/4712 [==============================] - 1130s - loss: 0.3547 - acc: 0.8742 - val_loss: 0.6752 - val_acc: 0.8141\n",
      "Epoch 123/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3533 - acc: 0.8724 Epoch 00122: val_acc did not improve\n",
      "4712/4712 [==============================] - 321s - loss: 0.3546 - acc: 0.8722 - val_loss: 0.7007 - val_acc: 0.8078\n",
      "Epoch 124/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3555 - acc: 0.8752 Epoch 00123: val_acc did not improve\n",
      "4712/4712 [==============================] - 314s - loss: 0.3534 - acc: 0.8758 - val_loss: 0.6722 - val_acc: 0.8243\n",
      "Epoch 125/500\n",
      "4600/4712 [============================>.] - ETA: 6s - loss: 0.3521 - acc: 0.8817 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b61156c5aa59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msaveBestModel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m### PREDICTION ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sruti/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/sruti/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1545\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m                             verbose=0)\n\u001b[0m\u001b[1;32m   1548\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sruti/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m   1181\u001b[0m         return self._test_loop(f, ins,\n\u001b[1;32m   1182\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                                verbose=verbose)\n\u001b[0m\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sruti/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    940\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sruti/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sruti/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sruti/anaconda3/lib/python3.5/site-packages/theano/ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "nb_classes = 62 # A-Z, a-z and 0-9\n",
    "nb_epoch = 500\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 40, 25\n",
    "\n",
    "# Path of data files\n",
    "path = os.getcwd()\n",
    "\n",
    "# Load the preprocessed data and labels\n",
    "X_train_all = np.load(os.getcwd()+\"/data/\"+\"/trainPreproc_\"+str(img_rows)+\"_\"+str(img_cols)+\".npy\")\n",
    "Y_train_all = np.load(os.getcwd()+\"/data/\"+\"/labelsPreproc.npy\")\n",
    "\n",
    "# Do multiple learnings and predictions with the aim of averaging them\n",
    "for runID in range (18):    \n",
    "    # Split in train and validation sets to get the \"best\" model.\n",
    "    X_train, X_val, Y_train, Y_val = \\\n",
    "        train_test_split(X_train_all, Y_train_all, test_size=0.25, stratify=np.argmax(Y_train_all, axis=1))\n",
    "   \n",
    "                             \n",
    "    # Parametrize the image augmentation class\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range = 20,\n",
    "        width_shift_range = 0.15,\n",
    "        height_shift_range = 0.15,\n",
    "        shear_range = 0.4,\n",
    "        zoom_range = 0.3,                    \n",
    "        channel_shift_range = 0.1,\n",
    "        channel_flip = True, \n",
    "        channel_flip_max = 1.) \n",
    "\n",
    "    ### CNN MODEL ###\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same', init='he_normal', activation = 'relu', input_shape=(1,img_rows, img_cols)))\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same', init='he_normal', activation = 'relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(256, 3, 3, border_mode='same', init='he_normal', activation = 'relu'))\n",
    "    model.add(Convolution2D(256, 3, 3, border_mode='same', init='he_normal', activation = 'relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(512, 3, 3, border_mode='same', init='he_normal', activation = 'relu'))\n",
    "    model.add(Convolution2D(512, 3, 3, border_mode='same', init='he_normal', activation = 'relu'))\n",
    "    model.add(Convolution2D(512, 3, 3, border_mode='same', init='he_normal', activation = 'relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, init='he_normal', activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, init='he_normal', activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, init='he_normal', activation = 'softmax'))\n",
    "\n",
    "    ### LEARNING ###\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adadelta',  \n",
    "                  metrics=[\"accuracy\"])\n",
    "            \n",
    "    saveBestModel = ModelCheckpoint(\"best.kerasModelWeights\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    # Make the model learn using the image generator\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        samples_per_epoch=len(X_train),\n",
    "                        nb_epoch=nb_epoch, \n",
    "                        validation_data=(X_val, Y_val),\n",
    "                        callbacks=[saveBestModel],\n",
    "                        verbose=1)\n",
    "\n",
    "    ### PREDICTION ###\n",
    "                        \n",
    "    # Load the model with the highest validation accuracy\n",
    "    model.load_weights(\"best.kerasModelWeights\")\n",
    "\n",
    "    # Load Kaggle test set\n",
    "    X_test = np.load(os.getcwd()+\"/data/testPreproc_\"+str(img_rows)+\"_\"+str(img_cols)+\".npy\")\n",
    "\n",
    "    # Predict the class (give the index in the one-hot vector of the most probable class)\n",
    "    Y_test_pred = model.predict_classes(X_test)\n",
    "    \n",
    "    # Translate integers to character labels\n",
    "    vInt2label = np.vectorize(int2label)\n",
    "    Y_test_pred = vInt2label(Y_test_pred)\n",
    "    \n",
    "    # Save the predicitions in Kaggle format\n",
    "    np.savetxt(os.getcwd()+\"/data/CNN_pred_\"+str(runID)+\".csv\", np.c_[range(6284,len(Y_test_pred)+6284),Y_test_pred], delimiter=',', header = 'ID,Class', comments = '', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6220/6220 [==============================] - 127s   \n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"best.kerasModelWeights\")\n",
    "\n",
    "    # Load Kaggle test set\n",
    "X_test = np.load(os.getcwd()+\"/data/testPreproc_\"+str(img_rows)+\"_\"+str(img_cols)+\".npy\")\n",
    "\n",
    "    # Predict the class (give the index in the one-hot vector of the most probable class)\n",
    "Y_test_pred = model.predict_classes(X_test)\n",
    "    \n",
    "    # Translate integers to character labels\n",
    "vInt2label = np.vectorize(int2label)\n",
    "Y_test_pred = vInt2label(Y_test_pred)\n",
    "    \n",
    "    # Save the predicitions in Kaggle format\n",
    "np.savetxt(os.getcwd()+\"/data/CNN_new4025.csv\", np.c_[range(6284,len(Y_test_pred)+6284),Y_test_pred], delimiter=',', header = 'ID,Class', comments = '', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of prediction files in path\n",
    "allPredsFiles = glob.glob(os.getcwd()+\"/data/CNN_pred_*.csv\")\n",
    "\n",
    "allPreds = []\n",
    "\n",
    "for file in allPredsFiles:\n",
    "    preds = pd.read_csv(file).values\n",
    "    predictionTemplate = preds \n",
    "    allPreds.append(preds[:,1:2]) \n",
    "\n",
    "# Stacks all the predictions \n",
    "predsStacked = np.hstack(allPreds) \n",
    "\n",
    "# Create the averaged result array, copying the template\n",
    "predsAveraged = np.array(predictionTemplate)\n",
    "\n",
    "# For each prediction, get the most frequent one\n",
    "for i in range(predsStacked.shape[0]):\n",
    "    (values,counts) = np.unique(predsStacked[i], return_counts=True) \n",
    "    ind=np.argmax(counts) \n",
    "    predsAveraged[i,1] = values[ind]  # gets the most frequent label\n",
    "    \n",
    "# Save the averaged predicitions in csv file\n",
    "np.savetxt(os.getcwd()+\"/data/avg_pred.csv\", np.c_[predsAveraged], delimiter=',', header = 'ID,Class', comments = '', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
